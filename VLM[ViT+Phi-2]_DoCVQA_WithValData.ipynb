{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to add Validation data in the training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Modified Function Header\n",
    "##def train_projection_layer(dataloader, projector, val_dataloader=None, epochs=3):\n",
    "##Add this block at the end of each epoch\n",
    "###print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | ANLS: {avg_anls:.4f}\")\n",
    "\n",
    "\n",
    "        if val_dataloader:\n",
    "            projector.eval()\n",
    "            val_loss = 0\n",
    "            val_anls = []\n",
    "            with torch.no_grad():\n",
    "                for batch in val_dataloader:\n",
    "                    images = batch[\"image\"].to(device)\n",
    "                    questions = batch[\"question\"]\n",
    "                    answers = batch[\"answer\"]\n",
    "\n",
    "                    vit_out = vit_model(pixel_values=images)\n",
    "                    cls_token = vit_out.last_hidden_state[:, 0, :]\n",
    "                    projected_embed = projector(cls_token).unsqueeze(1).to(torch.float16)\n",
    "\n",
    "                    prompts = [f\"Question: {q.strip()} Answer:\" for q in questions]\n",
    "                    full_texts = [f\"{p} {a.strip()}\" for p, a in zip(prompts, answers)]\n",
    "\n",
    "                    inputs = phi_tokenizer(full_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "                    input_ids = inputs.input_ids.to(device)\n",
    "                    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "                    with phi_tokenizer.as_target_tokenizer():\n",
    "                        prompt_ids = phi_tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n",
    "\n",
    "                    labels = input_ids.clone()\n",
    "                    for i in range(labels.shape[0]):\n",
    "                        prompt_len = (prompt_ids[i] != phi_tokenizer.pad_token_id).sum()\n",
    "                        labels[i, :prompt_len] = -100\n",
    "\n",
    "                    token_embeds = phi_model.model.embed_tokens(input_ids).to(torch.float16)\n",
    "                    inputs_embeds = torch.cat([projected_embed, token_embeds], dim=1)\n",
    "\n",
    "                    attention_mask = torch.cat([\n",
    "                        torch.ones((attention_mask.shape[0], 1), dtype=torch.long).to(device),\n",
    "                        attention_mask\n",
    "                    ], dim=1)\n",
    "                    labels = torch.cat([\n",
    "                        torch.full((labels.shape[0], 1), fill_value=-100).to(device),\n",
    "                        labels\n",
    "                    ], dim=1)\n",
    "\n",
    "                    outputs = phi_model(\n",
    "                        inputs_embeds=inputs_embeds,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    val_loss += outputs.loss.item()\n",
    "\n",
    "                    generated_ids = phi_model.generate(\n",
    "                        inputs_embeds=inputs_embeds,\n",
    "                        attention_mask=attention_mask,\n",
    "                        max_new_tokens=50,\n",
    "                        do_sample=False\n",
    "                    )\n",
    "                    decoded_preds = phi_tokenizer.batch_decode(generated_ids[:, 1:], skip_special_tokens=True)\n",
    "                    decoded_preds = [pred.replace(prompt, \"\").strip() for pred, prompt in zip(decoded_preds, prompts)]\n",
    "                    val_anls.append(compute_anls(decoded_preds, answers))\n",
    "\n",
    "            print(f\"    [Validation] Loss: {val_loss / len(val_dataloader):.4f} | ANLS: {np.mean(val_anls):.4f}\")\n",
    "            projector.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
